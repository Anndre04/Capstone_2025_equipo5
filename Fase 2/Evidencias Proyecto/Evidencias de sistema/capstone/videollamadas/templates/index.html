{% extends "base.html" %}
{% block content %}
<h2>Videollamada: {{ tutoria }}</h2>
<p>Email: {{ request.user.email }}</p>

<p id="status" style="font-weight: bold; color: green;">Conectando...</p>

<div id="video-container" style="display: flex; justify-content: center; gap: 1rem; margin-top: 1rem; flex-wrap: wrap;">
<canvas id="recordingCanvas" style="display: none;"></canvas>
Â  <div style="position: relative;">
Â  Â  <video id="localVideo" autoplay muted playsinline style="width: 300px; height: 200px; border-radius: 10px; background: #000; object-fit: cover;"></video>
Â  Â  <span style="position: absolute; bottom: 8px; left: 10px; color: white; font-size: 14px;">TÃº</span>
Â  </div>

Â  <div style="position: relative;">
Â  Â  <video id="remoteVideo" autoplay playsinline style="width: 300px; height: 200px; border-radius: 10px; background: #000; object-fit: cover;"></video>
Â  Â  <span style="position: absolute; bottom: 8px; left: 10px; color: white; font-size: 14px;">Otro usuario</span>
Â  </div>
</div>

<div style="margin-top: 1.5rem; text-align: center;">
Â  <button id="toggleCam">ğŸ¥ CÃ¡mara</button>
Â  <button id="toggleMic">ğŸ¤ MicrÃ³fono</button>
Â  <button id="shareScreenBtn">ğŸ–¥ï¸ Compartir Pantalla</button>
Â  <button id="recordBtn">âºï¸ Grabar</button>
</div>

<script>
const GRABAR_URL = "{% url 'iniciar_grabacion' tutoria.id %}";
const DETENER_URL = "{% url 'detener_grabacion' tutoria.id %}";
const TUTORIA_ID = "{{ tutoria.id }}";
const USER_ID = "{{ request.user.id }}";
const ROLE = "{% if request.user == tutoria.tutor.usuario %}tutor{% else %}estudiante{% endif %}";

const wsScheme = window.location.protocol === "https:" ? "wss" : "ws";
const wsPath = `${wsScheme}://${window.location.host}/ws/tutoria/${TUTORIA_ID}/`;
let socket;

let localStream;
let peerConnection;
let screenStream;
let recordingPeer;
let recordingCanvas;
let ctx;
let recordingStream;
let animationFrameId;
let pendingIceCandidates = []; // buffer temporal de candidatos que llegan antes del remoteDescription


// --- ğŸ“ CAMBIO 1: Almacenar el track de audio remoto para la mezcla ---
let remoteAudioTrack;
let remoteVideoTrack;  // <- AÃ‘ADIR ESTA LÃNEA

const localVideo = document.getElementById("localVideo");
const remoteVideo = document.getElementById("remoteVideo");
const statusEl = document.getElementById("status");
const recordBtn = document.getElementById("recordBtn");

// ICE servers
const configuration = { iceServers: [{ urls: "stun:stun.l.google.com:19302" }] };

// =====================
// Inicializar CANVAS (MOVEMOS ESTO FUERA DE initMedia)
// =====================
async function initCanvas() {
    recordingCanvas = document.getElementById("recordingCanvas");
    
    // **AÃ±ade una verificaciÃ³n de seguridad**
    if (!recordingCanvas) {
        console.error("El elemento 'recordingCanvas' no se encontrÃ³ en el DOM.");
        return;
    }
    
    recordingCanvas.width = 600; 
    recordingCanvas.height = 200; 
    ctx = recordingCanvas.getContext("2d");
    console.log("Canvas de grabaciÃ³n inicializado.");
}

// =====================
// Inicializar cÃ¡mara y mic (SIMPLIFICADA)
// =====================
async function initMedia() {
    try {
        const audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const videoStream = await navigator.mediaDevices.getUserMedia({ video: true });
        localStream = new MediaStream([...audioStream.getAudioTracks(), ...videoStream.getVideoTracks()]);
        localVideo.srcObject = localStream;
        // No hacer nada mÃ¡s aquÃ­
    } catch (err) {
        console.error("Error accediendo a cÃ¡mara/micrÃ³fono:", err);
    }
}

// Llama a esta funciÃ³n para iniciar la composiciÃ³n de video
function startCanvasDrawing() {
    function drawFrame() {
        // Limpia el canvas
        ctx.clearRect(0, 0, recordingCanvas.width, recordingCanvas.height);

        // 1. Dibuja el video local (posiciÃ³n 0, 0)
        // Usamos readyState para asegurarnos de que el video tiene datos
        if (localVideo.readyState >= 2) { 
            ctx.drawImage(localVideo, 0, 0, 300, 200);
        }

        // 2. Dibuja el video remoto (posiciÃ³n 300, 0)
        if (remoteVideo.readyState >= 2) {
            ctx.drawImage(remoteVideo, 300, 0, 300, 200);
        }

        // Repite el dibujo al siguiente frame de la pantalla
        animationFrameId = requestAnimationFrame(drawFrame);
    }
    
    // Inicia el bucle
    drawFrame();
}

function stopCanvasDrawing() {
    cancelAnimationFrame(animationFrameId);
}

// =====================
// Crear PeerConnection
// =====================
function createPeerConnection() {
Â  Â  peerConnection = new RTCPeerConnection(configuration);
Â  Â  localStream.getTracks().forEach(track => peerConnection.addTrack(track, localStream));

Â  Â  peerConnection.ontrack = e => {
    remoteVideo.srcObject = e.streams[0];
    
        // --- ğŸ“ CAMBIO 2: Capturar tracks originales ---
        if (e.track.kind === 'audio') {
            remoteAudioTrack = e.track;
        } else if (e.track.kind === 'video') {
            remoteVideoTrack = e.track;  // <- CAPTURAR TRACK DE VIDEO ORIGINAL
            console.log("Track de video remoto capturado:", remoteVideoTrack.id);
        }
    };

Â  Â  peerConnection.onicecandidate = event => {
Â  Â  Â  Â  if (event.candidate) socket.send(JSON.stringify({ type: "ice-candidate", candidate: event.candidate }));
Â  Â  };

Â  Â  peerConnection.onconnectionstatechange = () => {
Â  Â  Â  Â  console.log("Connection State:", peerConnection.connectionState);
Â  Â  Â  Â  if (peerConnection.connectionState === "disconnected") {
Â  Â  Â  Â  Â  Â  statusEl.textContent = "Desconectado âŒ"; statusEl.style.color = "red";
Â  Â  Â  Â  }
Â  Â  Â  Â  if (peerConnection.connectionState === "connected") {
Â  Â  Â  Â  Â  Â  statusEl.textContent = "Conectado âœ…"; statusEl.style.color = "green";
Â  Â  Â  Â  }
Â  Â  };
}

// =====================
// WebSocket con reconexiÃ³n
// (sin cambios relevantes en esta secciÃ³n)
// =====================
function connectWebSocket() {
    socket = new WebSocket(wsPath);

    socket.onopen = () => {
        statusEl.textContent = "Conectado âœ…"; statusEl.style.color = "green";
        socket.send(JSON.stringify({ type: "join", user_id: USER_ID, role: ROLE }));
    };

    socket.onclose = () => {
        statusEl.textContent = "Reconectando..."; statusEl.style.color = "orange";
        setTimeout(connectWebSocket, 2000);
    };

    socket.onmessage = async (event) => {
        const data = JSON.parse(event.data);

        try {
            switch (data.type) {
                case "user_joined":
                    // Si no hay pc, crearlo (el resto del flujo sigue igual)
                    if (!peerConnection) {
                        createPeerConnection();
                        if (ROLE === "tutor") {
                            const offer = await peerConnection.createOffer();
                            await peerConnection.setLocalDescription(offer);
                            socket.send(JSON.stringify({ type: "offer", sdp: offer }));
                        }
                    }
                    break;

                case "offer":
                    if (!peerConnection) createPeerConnection();

                    // data.sdp se espera como objeto { type: 'offer', sdp: 'v=0...' }
                    await peerConnection.setRemoteDescription(data.sdp);
                    // despuÃ©s de setRemoteDescription, procesamos candidatos pendientes
                    await flushPendingIceCandidates();

                    const answer = await peerConnection.createAnswer();
                    await peerConnection.setLocalDescription(answer);
                    socket.send(JSON.stringify({ type: "answer", sdp: answer }));
                    break;

                case "answer":
                    // AsegÃºrate de que peerConnection exista
                    if (!peerConnection) {
                        console.warn("Recibido 'answer' pero peerConnection no existe aÃºn. Creando...");
                        createPeerConnection();
                    }
                    await peerConnection.setRemoteDescription(data.sdp);
                    await flushPendingIceCandidates();
                    break;

                case "ice-candidate":
                    // defensivo: data.candidate puede ser undefined
                    if (!data.candidate) break;

                    // Si no existe pc o no tiene remoteDescription (aÃºn), bufferizar
                    if (!peerConnection || !peerConnection.remoteDescription) {
                        pendingIceCandidates.push(data.candidate);
                        console.log("ICE candidate buffered (no remoteDescription aÃºn). total buffered:", pendingIceCandidates.length);
                    } else {
                        try {
                            // some browsers expect RTCIceCandidate instance
                            await peerConnection.addIceCandidate(new RTCIceCandidate(data.candidate));
                            console.log("ICE candidate aÃ±adido correctamente.");
                        } catch (err) {
                            console.warn("Error aÃ±adiendo ICE candidate inmediato:", err);
                        }
                    }
                    break;

                case "user_left":
                    remoteVideo.srcObject = null;
                    remoteVideoTrack = null;
                    remoteAudioTrack = null;
                    statusEl.textContent = "El otro usuario saliÃ³ âŒ"; statusEl.style.color = "red";
                    break;
            }
        } catch (err) {
            console.error("Error manejando mensaje WS:", err, data);
        }
    };
}

// --- Helper: vacÃ­a los candidatos pendientes ---
async function flushPendingIceCandidates() {
    if (!peerConnection) {
        pendingIceCandidates = []; // descartamos si no hay pc
        return;
    }
    if (!pendingIceCandidates.length) return;

    console.log("Flushing", pendingIceCandidates.length, "pending ICE candidates...");
    // procesar en orden
    while (pendingIceCandidates.length) {
        const candidate = pendingIceCandidates.shift();
        try {
            await peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
        } catch (err) {
            console.warn("Error al aÃ±adir pending candidate:", err, candidate);
        }
    }
}

// =====================
// Botones cÃ¡mara/mic/pantalla
// (sin cambios relevantes en esta secciÃ³n)
// =====================
document.getElementById("toggleCam").addEventListener("click", () => {
Â  Â  localStream.getVideoTracks().forEach(track => track.enabled = !track.enabled);
});
document.getElementById("toggleMic").addEventListener("click", () => {
Â  Â  localStream.getAudioTracks().forEach(track => track.enabled = !track.enabled);
});
document.getElementById("shareScreenBtn").addEventListener("click", async () => {
Â  Â  try {
Â  Â  Â  Â  screenStream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: false });
Â  Â  Â  Â  localVideo.srcObject = screenStream;
Â  Â  Â  Â  
Â  Â  Â  Â  // --- El video de la pantalla reemplaza al video de la cÃ¡mara en el PC principal
Â  Â  Â  Â  const sender = peerConnection.getSenders().find(s => s.track.kind === 'video');
Â  Â  Â  Â  if (sender) {
Â  Â  Â  Â  Â  Â  sender.replaceTrack(screenStream.getVideoTracks()[0]);
Â  Â  Â  Â  }

Â  Â  Â  Â  screenStream.getVideoTracks()[0].addEventListener("ended", () => {
Â  Â  Â  Â  Â  Â  // Volver a la cÃ¡mara despuÃ©s de dejar de compartir
Â  Â  Â  Â  Â  Â  localVideo.srcObject = localStream;
Â  Â  Â  Â  Â  Â  const cameraTrack = localStream.getVideoTracks()[0];
Â  Â  Â  Â  Â  Â  const screenSender = peerConnection.getSenders().find(s => s.track.kind === 'video');
Â  Â  Â  Â  Â  Â  if (screenSender) screenSender.replaceTrack(cameraTrack);
Â  Â  Â  Â  Â  Â  screenStream = null;
Â  Â  Â  Â  });
Â  Â  } catch (err) { console.error("Error compartiendo pantalla:", err); }
});

// =====================
// --- ğŸ“ CAMBIO 3: FunciÃ³n de Mezcla de Audio (Web Audio API) ---
// =====================
// =====================
// --- FUNCIÃ“N DE MEZCLA DE AUDIO (CORREGIDA) ---
// =====================
function getMixedStream() {
    const localAudioTrack = localStream.getAudioTracks()[0];
    
    // Si no hay track remoto, creamos un nuevo stream solo con el track local
    if (!remoteAudioTrack) {
        console.warn("No hay track de audio remoto para mezclar. Solo se grabarÃ¡ audio local.");
        // âœ… SOLUCIÃ“N: Devolvemos un MediaStream.
        return new MediaStream([localAudioTrack]); 
    }

    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const destination = audioCtx.createMediaStreamDestination();

    // 1. Fuente de audio local
    const localAudioSource = audioCtx.createMediaStreamSource(
        new MediaStream([localAudioTrack])
    );
    localAudioSource.connect(destination);

    // 2. Fuente de audio remota
    const remoteAudioSource = audioCtx.createMediaStreamSource(
        new MediaStream([remoteAudioTrack])
    );
    remoteAudioSource.connect(destination);

    // âœ… SOLUCIÃ“N: Devolvemos el MediaStream del destino.
    return destination.stream; 
}

// =====================
// GrabaciÃ³n servidor (LÃ³gica actualizada)
// =====================
recordBtn.addEventListener("click", async () => {
    if (!recordingPeer) {
        // 1. Verificar soporte
        if (!recordingCanvas.captureStream) {
             alert("El navegador no soporta captureStream().");
             return;
        }
        
        // 2. Iniciar dibujo y obtener tracks
        startCanvasDrawing();

        // Obtener el Ãºnico Video Track del canvas
        const canvasVideoTrack = recordingCanvas.captureStream(30).getVideoTracks()[0]; // 30 FPS

        let mixedAudioTrack;
        try {
            // audioStream ahora SIEMPRE serÃ¡ un MediaStream
            const audioStream = getMixedStream(); 
            
            // Esto ahora es seguro y SIEMPRE devolverÃ¡ un track vÃ¡lido
            mixedAudioTrack = audioStream.getAudioTracks()[0]; 
        } catch (e) {
            console.error("Error al obtener stream mezclado:", e);
            stopCanvasDrawing(); 
            return;
        }

        // 3. CREAR EL MEDIASTREAM FINAL COMBINADO
        recordingStream = new MediaStream([canvasVideoTrack, mixedAudioTrack]);

        // 4. INICIAR LA CONEXIÃ“N WEBRTC (AÃ‘ADIR TRACKS)
        const pc = new RTCPeerConnection(configuration);
        recordingPeer = pc; 

        recordingStream.getTracks().forEach(track => {
            pc.addTrack(track, recordingStream);
        });

        // 5. CREAR Y ENVIAR LA OFERTA AL SERVIDOR (ğŸŒŸ CORRECCIÃ“N APLICADA AQUÃ)
        try {
            const offer = await pc.createOffer();
            await pc.setLocalDescription(offer);

            recordBtn.textContent = "Grabando... ğŸ”´";
            recordBtn.disabled = true;

            const resp = await fetch(GRABAR_URL, {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                // âœ… CORRECCIÃ“N: Usamos el objeto 'offer' directamente.
                body: JSON.stringify({ sdp: offer }) 
            });
            
            const data = await resp.json();

            if (resp.ok) {
                // 6. RECIBIR LA RESPUESTA (ANSWER) DEL SERVIDOR
                await pc.setRemoteDescription(new RTCSessionDescription({
                    type: data.type,
                    sdp: data.sdp
                }));
                recordBtn.textContent = "â¹ï¸ Detener GrabaciÃ³n";
                recordBtn.disabled = false;
                console.log("âœ… GrabaciÃ³n iniciada con Ã©xito. Respuesta del servidor recibida.");
            } else {
                console.error("âŒ Error al iniciar la grabaciÃ³n en el servidor:", data.message || data.status);
                alert("Error al iniciar grabaciÃ³n. Revisa los logs del servidor.");
                await cleanupRecording(pc); 
            }

        } catch (e) {
            console.error("Error en el proceso WebRTC o Fetch:", e);
            await cleanupRecording(pc);
        }

    } else {
        // LÃ³gica para DETENER
        recordBtn.textContent = "Deteniendo...";
        recordBtn.disabled = true;

        await fetch(DETENER_URL, { method: "POST" });
        await cleanupRecording(recordingPeer);
        
        recordBtn.textContent = "âºï¸ Grabar";
        recordBtn.disabled = false;
        console.log("ğŸ”´ GrabaciÃ³n detenida.");
    }
});

// --- FUNCIÃ“N DE LIMPIEZA CENTRALIZADA ---
async function cleanupRecording(pc) {
    stopCanvasDrawing(); 
    if (recordingStream) {
        // Detener ambos tracks explÃ­citamente para liberar recursos
        recordingStream.getTracks().forEach(track => track.stop());
    }
    if (pc) {
        pc.close();
    }
    recordingPeer = null;
}
// =====================
// Iniciar todo (CORREGIDO) ğŸš€
// =====================
async function startApp() {
    console.log("Iniciando componentes de la aplicaciÃ³n...");
    
    // 1. Inicializar cÃ¡mara/mic
    await initMedia(); 
    
    // 2. Inicializar el CANVAS y su contexto (Â¡AQUÃ ESTÃ LA SOLUCIÃ“N!)
    await initCanvas(); 
    
    // 3. Conectar WebSockets
    connectWebSocket();
    console.log("AplicaciÃ³n lista.");
}

// Llama a la nueva funciÃ³n principal de inicio
startApp();
</script>
{% endblock %}